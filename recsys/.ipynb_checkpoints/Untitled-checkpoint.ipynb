{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94c89382",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/soycasi/.local/share/virtualenvs/Entornos-rWKTcBuY/lib/python3.6/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim\n",
    "import spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6842a0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nlp = spacy.load('/usr/local/lib/python3.6/dist-packages/es_core_news_md/es_core_news_md-2.1.0')\n",
    "df_news = pd.read_csv(\"Data/training_data.csv\")\n",
    "df_news.drop('Unnamed: 0', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9c25fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 812 entries, 0 to 811\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   review  812 non-null    object\n",
      " 1   score   812 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 12.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df_news.head(2)\n",
    "df_news.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bec1011",
   "metadata": {},
   "outputs": [],
   "source": [
    "black_list = ['más', 'mas', 'unir', 'paises', 'pais', 'espa', 'no', 'os', 'a', 'compa', 'acompa', 'off', 'and', 'grecia', 'the','it', 'to',\n",
    "              'd',  'et',  'dame',  'il',  'dans', 'that',  'as',   'for',  'it',  'elections',  'would',  'this',  'with', 'york', 'obama', 'chavez', 'gadafi']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48cb4a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaner(word):\n",
    "  word = re.sub(r'((http|https)\\:\\/\\/)?[a-zA-Z0-9\\.\\/\\?\\:@\\-_=#]+\\.([a-zA-Z]){2,6}([a-zA-Z0-9\\.\\&\\/\\?\\:@\\-_=#])*', '', word, flags=re.MULTILINE)\n",
    "  word = re.sub(r'(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', \"\", word)\n",
    "  word = re.sub(r'ee.uu', 'eeuu', word)\n",
    "  word = re.sub(r'\\#\\.', '', word)\n",
    "  word = re.sub(r'\\n', '', word)\n",
    "  word = re.sub(r',', '', word)\n",
    "  word = re.sub(r'\\-', ' ', word)\n",
    "  word = re.sub(r'\\.{3}', ' ', word)\n",
    "  word = re.sub(r'a{2,}', 'a', word)\n",
    "  word = re.sub(r'é{2,}', 'é', word)\n",
    "  word = re.sub(r'i{2,}', 'i', word)\n",
    "  word = re.sub(r'ja{2,}', 'ja', word) \n",
    "  word = re.sub(r'á', 'a', word)\n",
    "  word = re.sub(r'é', 'e', word)\n",
    "  word = re.sub(r'í', 'i', word)\n",
    "  word = re.sub(r'ó', 'o', word)\n",
    "  word = re.sub(r'ú', 'u', word)  \n",
    "  word = re.sub('[^a-zA-Z]', ' ', word)\n",
    "  list_word_clean = []\n",
    "  for w1 in word.split(\" \"):\n",
    "    if  w1.lower() not in stopwords:\n",
    "      list_word_clean.append(w1.lower())\n",
    "\n",
    "  bigram_list = bigram[list_word_clean]\n",
    "  out_text = lemmatization(\" \".join(bigram_list))\n",
    "  return out_text\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ']):\n",
    "    texts_out = [ token.text for token in nlp(texts) if token.pos_ in \n",
    "                 allowed_postags and token.text not in black_list and len(token.text)>2]\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcdb59f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
